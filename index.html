<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Enhanced OCR with Progress</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
    }
    #preview, #processed {
      margin: 20px auto;
      max-width: 100%;
      max-height: 300px;
      border: 1px solid #ddd;
    }
    textarea {
      width: 90%;
      height: 200px;
      margin-top: 20px;
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 5px;
      font-size: 16px;
    }
    button {
      padding: 10px 20px;
      margin-top: 10px;
      background-color: #007BFF;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    button:hover {
      background-color: #0056b3;
    }
    #progress {
      margin-top: 10px;
      font-size: 18px;
      color: #007BFF;
    }
  </style>
</head>
<body>
  <h1>Enhanced OCR with Progress</h1>
  <input type="file" id="imageInput" accept="image/*">
  <canvas id="previewCanvas" style="display: none;"></canvas>
  <img id="preview" src="" alt="Original Image Preview">
  <img id="processed" src="" alt="Processed Image Preview">
  <button id="enhanceButton" disabled>Enhance Image Quality</button>
  <button id="extractButton" disabled>Extract Text</button>
  <p id="progress"></p>
  <textarea id="output" placeholder="Extracted text will appear here..."></textarea>

  <!-- Include OpenCV.js -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <script>
    const imageInput = document.getElementById("imageInput");
    const preview = document.getElementById("preview");
    const processed = document.getElementById("processed");
    const previewCanvas = document.getElementById("previewCanvas");
    const enhanceButton = document.getElementById("enhanceButton");
    const extractButton = document.getElementById("extractButton");
    const progress = document.getElementById("progress");
    const output = document.getElementById("output");

    let originalImageBase64 = "";
    let enhancedImageBase64 = "";

    // Utility: Update progress
    function updateProgress(message) {
      progress.textContent = message;
    }

    // Enable Enhance Button after image upload
    imageInput.addEventListener("change", function () {
      const file = this.files[0];
      if (file) {
        const reader = new FileReader();
        reader.onload = function (e) {
          preview.src = e.target.result; // Show original image
          processed.src = ""; // Clear processed preview
          enhancedImageBase64 = ""; // Clear previous enhanced image
          enhanceButton.disabled = false; // Enable Enhance Button
          extractButton.disabled = true; // Disable Extract Button
          originalImageBase64 = e.target.result.split(",")[1]; // Save Base64 of original image
          updateProgress("Image uploaded successfully!");
        };
        reader.readAsDataURL(file);
      }
    });

    // Process Image with OpenCV.js
    async function processImage(imgElement) {
      return new Promise((resolve, reject) => {
        cv['onRuntimeInitialized'] = () => {
          const src = cv.imread(imgElement);
          const dst = new cv.Mat();

          try {
            // Grayscale conversion
            updateProgress("10% - Converting to grayscale...");
            cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY, 0);

            // Histogram equalization
            updateProgress("50% - Equalizing histogram...");
            cv.equalizeHist(dst, dst);

            // Enhance contrast
            updateProgress("90% - Enhancing contrast...");
            const alpha = 1.5; // Contrast control
            const beta = 20;  // Brightness control
            dst.convertTo(dst, -1, alpha, beta);

            // Convert processed image to Base64
            cv.imshow(previewCanvas, dst);
            previewCanvas.toBlob((blob) => {
              const reader = new FileReader();
              reader.onloadend = () => {
                resolve(reader.result.split(",")[1]); // Extract Base64
                updateProgress("100% - Enhancement completed!");
              };
              reader.readAsDataURL(blob);
            });

            src.delete();
            dst.delete();
          } catch (error) {
            reject(error);
          }
        };
      });
    }

    // Enhance Image Quality Button
    enhanceButton.addEventListener("click", async function () {
      if (!originalImageBase64) {
        updateProgress("Please upload an image first!");
        return;
      }

      try {
        updateProgress("Starting image quality enhancement...");
        enhancedImageBase64 = await processImage(preview);
        processed.src = "data:image/png;base64," + enhancedImageBase64; // Show processed image
        extractButton.disabled = false; // Enable Extract Button
      } catch (error) {
        updateProgress("Error during enhancement: " + error.message);
      }
    });

    // Extract Text from Enhanced Image
    extractButton.addEventListener("click", async function () {
      if (!enhancedImageBase64) {
        updateProgress("Please enhance the image quality first!");
        return;
      }

      const apiKey = "AIzaSyDnEZ6sNwbxVVVeQoTpEL22fep39b4I0oc"; // Replace with your API key
      const url = `https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`;

      const requestBody = {
        requests: [
          {
            image: {
              content: enhancedImageBase64,
            },
            features: [
              {
                type: "TEXT_DETECTION",
                maxResults: 1,
              },
            ],
          },
        ],
      };

      try {
        updateProgress("Extracting text from image...");
        const response = await fetch(url, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(requestBody),
        });

        const result = await response.json();

        if (
          result.responses &&
          result.responses[0] &&
          result.responses[0].fullTextAnnotation
        ) {
          output.value = result.responses[0].fullTextAnnotation.text;
          updateProgress("Text extraction successful!");
        } else {
          output.value = "No text detected in the image.";
          updateProgress("No text detected in the image.");
        }
      } catch (error) {
        updateProgress("Error occurred while extracting text. " + error.message);
        output.value = "Error occurred while extracting text.";
      }
    });
  </script>
</body>
</html>
